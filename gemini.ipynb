{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Implementation with Google Gemini, LangChain, and FAISS\n",
    "\n",
    "## Useful Documentation\n",
    "\n",
    "- [Google AI Generative API Docs](https://ai.google.dev/tutorials/python_quickstart)\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [FAISS GitHub Repository](https://github.com/facebookresearch/faiss)\n",
    "\n",
    "## Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q google-generativeai langchain faiss-cpu pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    CSVLoader,\n",
    "    JSONLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain.vectorstores import FAISS\n",
    "#from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "#from langchain.llms import GoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s: %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading and Preprocessing\n",
    "\n",
    "Document loading and preprocessing are crucial steps in the Retrieval-Augmented Generation (RAG) pipeline using LangChain. These steps involve loading documents from various sources, preprocessing them to make them suitable for retrieval and generation tasks, and then using them in the RAG pipeline.\n",
    "\n",
    "### Document Loading\n",
    "Document loading refers to the process of fetching documents from various sources such as files, databases, APIs, or web pages. LangChain provides various loaders to facilitate this process.\n",
    "\n",
    "### Example Loaders in LangChain:\n",
    "- File Loader: Loads documents from local files.\n",
    "- Web Loader: Loads documents from web pages.\n",
    "- Database Loader: Loads documents from databases.\n",
    "\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Preprocessing involves cleaning and transforming the loaded documents to make them suitable for retrieval and generation tasks. This may include steps such as tokenization, removing stop words, stemming, and converting text to lowercase.\n",
    "\n",
    "#### Steps in Document Loading and Preprocessing in RAG using LangChain:\n",
    "\n",
    "- Load Documents: Use appropriate loaders to fetch documents from the desired sources.\n",
    "- Preprocess Documents: Clean and transform the documents to prepare them for retrieval and generation.\n",
    "- Index Documents: Index the preprocessed documents to enable efficient retrieval.\n",
    "- Retrieve Documents: Retrieve relevant documents based on a query.\n",
    "- Generate Response: Use the retrieved documents to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_paths):\n",
    "    \"\"\"\n",
    "    Load documents from multiple file types with error handling\n",
    "\n",
    "    Args:\n",
    "        file_paths (list): List of file paths to load\n",
    "\n",
    "    Returns:\n",
    "        list: Loaded documents\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                logger.warning(f\"File not found: {path}\")\n",
    "                continue\n",
    "\n",
    "            if path.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(path)\n",
    "            elif path.endswith('.csv'):\n",
    "                loader = CSVLoader(path)\n",
    "            elif path.endswith('.json'):\n",
    "                loader = JSONLoader(path)\n",
    "            elif path.endswith('.txt'):\n",
    "                loader = TextLoader(path)\n",
    "            else:\n",
    "                logger.error(f\"Unsupported file type: {path}\")\n",
    "                continue\n",
    "\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not documents:\n",
    "        logger.warning(\"No documents were loaded\")\n",
    "\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Split documents into chunks with error handling\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of documents to split\n",
    "        chunk_size (int): Size of text chunks\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "\n",
    "    Returns:\n",
    "        list: Text chunks\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        chunks =  text_splitter.split_documents(documents)\n",
    "    \n",
    "        print(f\"Split into {len(chunks)} chunks\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Document splitting error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 11:26:20,980 - INFO: RAG System initialized successfully\n",
      "2025-01-23 11:26:20,983 - ERROR: Error loading datasets/menu.json: JSONLoader.__init__() missing 1 required positional argument: 'jq_schema'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 11:26:21,208 - INFO: Vector store created with 3 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact Information:\n",
      "Email: contact@coffeecorp.com\n",
      "Phone: +1-800-555-1234\n",
      "Website: www.coffeecorp.com\n",
      "Company Name: Coffee Corp\n",
      "Founded: 2005\n",
      "Headquarters: Seattle, USA\n",
      "Industry: Coffee\n",
      "Employees: 2000\n",
      "Mission: To provide the best coffee experience in the world.\n",
      "Vision: To be the leading coffee company globally.\n",
      "Values: Quality, Sustainability, Customer Satisfaction, Innovation\n",
      "Key Products:\n",
      "1. Espresso - A rich and bold coffee experience.\n",
      "2. Latte - A smooth blend of espresso and steamed milk.\n",
      "3. Cappuccino - A perfect balance of espresso, steamed milk, and foam.\n",
      "4. Cold Brew - A refreshing and smooth cold coffee.\n",
      "\n",
      "Company Achievements:\n",
      "- Awarded Best Coffee Company in 2019.\n",
      "- Recognized for sustainable practices by Green Coffee Magazine.\n",
      "- Achieved a customer satisfaction rate of 95%.\n",
      "RAG Response: 1. Espresso\n",
      "2. Latte\n",
      "3. Cappuccino\n",
      "4. Cold Brew\n"
     ]
    }
   ],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, model_name='models/embedding-001'):\n",
    "        \"\"\"\n",
    "        Initialize RAG system with embedding and generation models\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Gemini embedding model name\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate API key\n",
    "            if not os.getenv('GOOGLE_API_KEY'):\n",
    "                raise ValueError(\"Google API Key not found. Set GOOGLE_API_KEY in .env\")\n",
    "\n",
    "            genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "\n",
    "            self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "                model=model_name,\n",
    "                task_type='retrieval_document'\n",
    "            )\n",
    "            print(\"Embeddings initialized successfully!\")\n",
    "\n",
    "            self.llm = GoogleGenerativeAI(\n",
    "                model='gemini-pro',\n",
    "                temperature=0.7\n",
    "            )\n",
    "            print(\"LLM Model initialized successfully!\")\n",
    "\n",
    "            self.vectorstore = None\n",
    "            logger.info(\"RAG System initialized successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Initialization error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def create_vectorstore(self, documents):\n",
    "        \"\"\"\n",
    "        Create FAISS vector store from documents\n",
    "\n",
    "        Args:\n",
    "            documents (list): Preprocessed document chunks\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not documents:\n",
    "                raise ValueError(\"No documents provided for vector store\")\n",
    "\n",
    "            self.vectorstore = FAISS.from_documents(\n",
    "                documents,\n",
    "                self.embeddings\n",
    "            )\n",
    "            logger.info(f\"Vector store created with {len(documents)} chunks\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Vector store creation error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def similarity_search(self, query, k=5):\n",
    "        \"\"\"\n",
    "        Perform similarity search on vector store\n",
    "\n",
    "        Args:\n",
    "            query (str): Search query\n",
    "            k (int): Number of top results\n",
    "\n",
    "        Returns:\n",
    "            list: Top similar document chunks\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.vectorstore:\n",
    "                raise ValueError(\"Vector store not initialized\")\n",
    "\n",
    "            return self.vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Similarity search error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def query_documents(self, query, k=5):\n",
    "        \"\"\"\n",
    "        Create retrieval-based QA chain\n",
    "\n",
    "        Args:\n",
    "            query (str): User query\n",
    "            k (int): Number of context documents\n",
    "\n",
    "        Returns:\n",
    "            str: Generated response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.vectorstore:\n",
    "                raise ValueError(\"Vector store not initialized\")\n",
    "\n",
    "            retriever = self.vectorstore.as_retriever(\n",
    "                search_kwargs={'k': k}\n",
    "            )\n",
    "\n",
    "            qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                chain_type='stuff',\n",
    "                retriever=retriever\n",
    "            )\n",
    "\n",
    "            return qa_chain.run(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Document query error: {e}\")\n",
    "            return \"Unable to process query due to an error.\"\n",
    "\n",
    "# Example Usage\n",
    "def main():\n",
    "    try:\n",
    "        # File paths for different document types\n",
    "        file_paths = [            \n",
    "            'datasets/company_info.txt',\n",
    "            'datasets/menu.json'\n",
    "        ]\n",
    "\n",
    "        # Initialize RAG system\n",
    "        rag_system = RAGSystem()\n",
    "\n",
    "        # Load and preprocess documents\n",
    "        documents = load_documents(file_paths)\n",
    "        chunks = split_documents(documents)\n",
    "\n",
    "        # Create vector store\n",
    "        rag_system.create_vectorstore(chunks)\n",
    "\n",
    "        # Example queries\n",
    "        query1 = \"What is the main operation of Coffee Corp?\"\n",
    "        query2 = \"Summarize key products of Coffee Corp\"\n",
    "\n",
    "        # Perform similarity search\n",
    "        similar_docs = rag_system.similarity_search(query1)\n",
    "        for doc in similar_docs:\n",
    "            print(doc.page_content)\n",
    "\n",
    "        # Generate response using RAG\n",
    "        response = rag_system.query_documents(query2)\n",
    "        print(\"RAG Response:\", response)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
